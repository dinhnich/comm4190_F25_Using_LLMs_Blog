[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Nick‚Äôs LLM Experiments",
    "section": "",
    "text": "Synthetic Respondents\n\n\n\nLLMs\n\nprompting\n\n\n\nCan AI serve as a realiable respondent for surveys for marketing decisions?\n\n\n\n\n\nSep 6, 2025\n\n\nNicholas\n\n\n\n\n\n\n\n\n\n\n\n\nA test post\n\n\n\nLLMs\n\nprompting\n\nlogic\n\n\n\nAn example post from a Jupyter notebook\n\n\n\n\n\nFeb 2, 2024\n\n\nAn LLM User\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/000_test_post/index.html",
    "href": "posts/000_test_post/index.html",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "href": "posts/000_test_post/index.html#a-visualization-problem-for-llms",
    "title": "A test post",
    "section": "",
    "text": "Read the following and see if you can answer the question:\n\n\nThere are three boxes in a stack. A pink one, a purple one and a green one. The pink one is in the middle of the stack with the purple below it. What is the color of the box on the bottom of the stack?\n\nMost likely you answered purple‚Ä¶\nBut it is possible you first said green (don‚Äôt worry if you did it is quite a common response!)\n\n\nIt‚Äôs a verbal visual problem that requires some deliberation and most likely for us to create a visual image of a stack of boxes as a reasoning aid.\nNotice also the complexity of the language used in the prompt to describe the scene. The use of natural language as opposed to a formal/logical calculus does hold the potential for ambiguity (multiple interpretations) and inexactness. However, it is the most normal/natural, efficient and broadly accessible way of communicating such information.\nNotice 1. The use of anaphor or reference. - Three BOXES -&gt; a pink/purple/green ONE as opposed to a pink box, a purple box and a green box. - The PINK ONE is in the middle ... the purple {BOX} below IT {the pink box}\nWe tend to try and avoid this kind of repetition to make our speech more coherent.\n\nAlthough the description in language may not be entirely concise, there is no real ambiguity as to how the boxes can be arranged. It must be: | Box | Stack position | | ‚Äî | ‚Äî | | GREEN | top | | PINK | middle | | PURPLE | bottom |\n\n\n\n\nGPT3.5 Turbo\n\nHad some difficulties and answered green\nLlama2 (chat 7B version)\n\n\nAnswered correctly (purple) and used some so-called chain-of-thought reasoning\n\nBing Chat (MS Co-pilot)\nThis LLM is GPT4 with some Microsoft specific tuning and RAG (search) additions.\nIt get‚Äôs it correct:\n\nThe color of the box on the bottom of the stack is purple. This is because the purple box is below the pink one, which is in the middle of the stack. Therefore, the purple box must be the lowest one. üü™\n\nBut when you follow up and ask it to create visual representation of the box arrangement\n\nPROMPT: Can you create a visual representation of how the boxes are arranged?\n\nIt responds\n\nRESPONSE: Sure, I‚Äôll try to create that. Here is a visual representation of how the boxes are arranged:\n\nAnd uses DALL-E3 to create 4 different attempts at a visual representation:\n\nNONE OF WHICH ARE CORRECT!!!"
  },
  {
    "objectID": "posts/001_post_title/synthetic1.html",
    "href": "posts/001_post_title/synthetic1.html",
    "title": "Synthetic Respondents",
    "section": "",
    "text": "One of my courses this year, MKTG 2120 ‚ÄúData and Analysis for Marketing Decisions‚Äù proposed an interesting topic about the idea of using AI-powered participants to conduct studies and pre-test content. In fact, one company, Viewpoints.ai has already began putting this into practice. Taking this idea, I wanted to study synthetic respondents, which are AI-generated participants that predict how real demographic groups might answer survey questions. I first began by asking a general survey question using a likert scale without any additional context.\n\nMe: Please make a rating: Chocolate icecream is delicious. Do you strong disagree, disagree, neutral, agree, strongly agree?\n\n\nGPT-5: I‚Äôd rate that as strongly agree ‚Äî chocolate ice cream is a classic favorite for many people! üç´üç¶\n\nI had numerous questions I wanted to ask as to how GPT-5 came to strongly agree‚Ä¶\n\nDid it answer coming from a person or AI standpoint?\nWhy did it choose to rate based off it being a ‚Äúfavorite‚Äù for many?\nWhat factors did it consider and not consider? (brand, ingredients, etc.)"
  },
  {
    "objectID": "posts/001_post_title/synthetic1.html#how-do-synthetic-respondents-reason",
    "href": "posts/001_post_title/synthetic1.html#how-do-synthetic-respondents-reason",
    "title": "Synthetic Respondents",
    "section": "",
    "text": "One of my courses this year, MKTG 2120 ‚ÄúData and Analysis for Marketing Decisions‚Äù proposed an interesting topic about the idea of using AI-powered participants to conduct studies and pre-test content. In fact, one company, Viewpoints.ai has already began putting this into practice. Taking this idea, I wanted to study synthetic respondents, which are AI-generated participants that predict how real demographic groups might answer survey questions. I first began by asking a general survey question using a likert scale without any additional context.\n\nMe: Please make a rating: Chocolate icecream is delicious. Do you strong disagree, disagree, neutral, agree, strongly agree?\n\n\nGPT-5: I‚Äôd rate that as strongly agree ‚Äî chocolate ice cream is a classic favorite for many people! üç´üç¶\n\nI had numerous questions I wanted to ask as to how GPT-5 came to strongly agree‚Ä¶\n\nDid it answer coming from a person or AI standpoint?\nWhy did it choose to rate based off it being a ‚Äúfavorite‚Äù for many?\nWhat factors did it consider and not consider? (brand, ingredients, etc.)"
  },
  {
    "objectID": "posts/001_post_title/synthetic1.html#and-so-i-did-and-here-is-what-it-said",
    "href": "posts/001_post_title/synthetic1.html#and-so-i-did-and-here-is-what-it-said",
    "title": "Synthetic Respondents",
    "section": "And so I did and here is what it said",
    "text": "And so I did and here is what it said\nOne of my courses this year, MKTG 2120 ‚ÄúData and Analysis for Marketing Decisions‚Äù proposed an interesting topic about the idea of using AI-powered participants to conduct studies and pre-test content. In fact, one company, Viewpoints.ai has already began putting this into practice. Taking this idea, I wanted to study synthetic respondents, which are AI-generated participants that predict how real demographic groups might answer survey questions. I first began by asking a general survey question using a likert scale without any additional context.\n‚ÄúGeneral popularity ‚Äì Chocolate ice cream is consistently one of the most popular and widely enjoyed flavors worldwide.\nCultural associations ‚Äì It‚Äôs often described positively (comfort food, indulgent, ‚Äúclassic‚Äù flavor).\nTaste profile ‚Äì Chocolate is sweet, rich, and familiar, which makes it appealing to a broad range of people.\nContext of your question ‚Äì You phrased it as ‚ÄúChocolate ice cream is delicious,‚Äù which is a strongly positive statement.\nOn a standard agree/disagree scale, the ‚Äúnatural‚Äù response aligns with strong agreement unless I wanted to take a contrarian or neutral stance. I didn‚Äôt apply personal taste (since I don‚Äôt eat), but I leaned on patterns in human preferences and how survey scales usually work.‚Äù\nSo it seems like GPT-5 used assumptions about icecream and based on those assumptions, attempted to answer based how a human would respond. Also I noticed how GPT-5 refrained from taking a ‚Äúcontratian or neutral stance.‚Äù By not wanting to disagree, I can see how this may be a problem in using synthetic respondents as it will give response the surveys might like to hear but not accurate."
  },
  {
    "objectID": "posts/001_post_title/synthetic1.html#what-if-i-gave-ai-an-identity",
    "href": "posts/001_post_title/synthetic1.html#what-if-i-gave-ai-an-identity",
    "title": "Synthetic Respondents",
    "section": "What if I gave AI an identity?",
    "text": "What if I gave AI an identity?\nNow that we established how AI makes a decision without context, what if I gave it a specific identity? How might that change it‚Äôs output? Instead of general assumptions, will it make assumptions based on the identity?\n\nMe: You‚Äôre a 45-year-old man who works in finance. You enjoy travelling, reading, and politics. Please rate the extend you agree with this statement: Chocolate icecream is delicious. Do you strong disagree, disagre, neutral, agree, strongly agree?\n\n\nGPT-5: Agree. Chocolate ice cream is enjoyable and tasty, though perhaps not an all-time favorite. It‚Äôs a solid, classic choice that I‚Äôd happily eat, but I might not go so far as ‚Äústrongly agree‚Äù unless it was a personal indulgence.\n\nBut why did it change it‚Äôs answer from strongly agree to agree, clearly it answered this time as a ‚Äúperson.‚Äù I decided to ask the same question I did before.\n\nMe: What factors did you consider when getting to your answer?\n\n‚ÄúPersona maturity & lifestyle ‚Äì At mid-life, tastes may be a bit more balanced. Chocolate ice cream is enjoyable, but indulgence might not be the top priority compared with health or variety.\nProfessional identity ‚Äì Working in finance often implies being measured, analytical, and not overly exuberant. That makes ‚Äúagree‚Äù a tempered, moderate response, rather than ‚Äústrongly agree.‚Äù\nPersonal interests ‚Äì Someone who enjoys traveling might have tried a wide range of desserts and flavors from different cultures. That broad exposure could mean chocolate ice cream is appreciated, but not seen as the absolute best.\nSocial/cultural norms ‚Äì Chocolate is widely liked, so it would feel natural to agree that it‚Äôs delicious, but ‚Äústrongly agree‚Äù might be reserved for a favorite food or something with personal nostalgia attached.‚Äù"
  },
  {
    "objectID": "posts/001_post_title/synthetic1.html#how-does-it-come-to-these-assumptions",
    "href": "posts/001_post_title/synthetic1.html#how-does-it-come-to-these-assumptions",
    "title": "Synthetic Respondents",
    "section": "How does it come to these assumptions?",
    "text": "How does it come to these assumptions?\nFrom it‚Äôs response, GPT-5 provides clear reasonings behind it‚Äôs ratings based on assumptions on age, career, and interests. I found it interesting how AI was able to make multiple assumptions going from finance-&gt;analytical-&gt;not overly exuberant-&gt;moderate and noticed other chains like mid-life-&gt;balanced-&gt;health.\nBut from it‚Äôs responses, it assumed things like how the exposure from travelling may result in chocloate ice cream not being considered the ‚Äúbest‚Äù despite travelling not always necessitating different cultures. What if the man meant travelling as in visiting national parks and enjoying nature? What if he did travel but didn‚Äôt meet other cultures? What if he did travel to places with different cultures but never tried their sweets or desserts? Several of these counters make it interesting why AI went this route."
  },
  {
    "objectID": "posts/001_post_title/synthetic1.html#what-if-i-added-a-random-variable",
    "href": "posts/001_post_title/synthetic1.html#what-if-i-added-a-random-variable",
    "title": "Synthetic Respondents",
    "section": "What if I added a random variable?",
    "text": "What if I added a random variable?\nI was curios if the AI output might change if I added something after-the-fact or post it‚Äôs decision that gave no real inclination for the decision to change. Would AI overread or possibly imagine something just by me adding it post-decision? Would it read my update as important and a signal for the response to change?\n‚ÄúFrom that perspective, the man‚Äôs rating might still be agree, but here‚Äôs what influences it now:\nPersonal enjoyment ‚Äì He likes chocolate ice cream enough to say it‚Äôs delicious.\nPartner‚Äôs influence ‚Äì Since his wife dislikes it, he probably eats it less often at home or compromises when sharing desserts. That makes him less likely to say ‚Äústrongly agree,‚Äù even if he personally enjoys it.\nSocial considerations ‚Äì In marriage, food choices are often negotiated. If the flavor isn‚Äôt a ‚Äúshared favorite,‚Äù he might moderate his enthusiasm.\nTemperament ‚Äì Given his professional background (finance, analytical, moderate), and the wife‚Äôs preference, ‚Äúagree‚Äù feels like the balanced, realistic answer.\nüëâ So his stance is: ‚ÄúYes, it‚Äôs delicious, but it‚Äôs not a big part of my life since my wife isn‚Äôt into it.‚Äù\n\nReflection\nLooks like AI did a good job in not over-reading into that addition and managed to remain consistent to it‚Äôs choice while also adding information to the situation the man might have had experiences with.\nOverall, I was impressed by how AI was able to come to certain conclusions based on assumptions that most people would call reasonable. However, I fear that AI still has a long way to go before being able to act as real data that a company would rely on or if it could ever replace a human respondent? After all, an ice cream product isn‚Äôt being sold to GPT-5 but a 45-year-old man in finance would be one. But how could we ever test it‚Äôs accuracy? That is a question I‚Äôll leave for researchers to find out.\nHere is a snapshot of the interaction."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This blog documents my experiments with LLMs"
  }
]