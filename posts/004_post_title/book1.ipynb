{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4ca854c0-3c0b-4ce2-95c4-895ce3263c09",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Wishful mnemonics\"\n",
    "description: \"Is Bennett's proposition to study AI by studying evolution of the brain legitimate?\"\n",
    "author: \"Nicholas\"\n",
    "date: \"9/14/2025\"\n",
    "categories:\n",
    "  - Living with a Book\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675b2824-c946-4ad6-b874-8c5ebbd17a43",
   "metadata": {},
   "source": [
    "<img src=\"1.jpg\" width=\"100%\"/>\n",
    "\n",
    "## Wishful mnemonics\n",
    "\n",
    "As I was reading \"A Brief History of Intelligence\" by Max Bennett, I became curious about how he chose to introduce the idea about using evolution of the human brain to explain artificial intelligence. It reminded me of one of the readings I did for another COMM class called \"Common Sense vs. Data Science in Communications Research and Practice\" where we read a paper Melanie Mitchell's \"Why is AI harder than we think\" and her four fallacies regarding the study of AI.\n",
    "\n",
    "In fact, much of what Mitchell mentions is addressed by Bennett coincidentally such as how tasks such as emptying a dish washer is easy for humans but difficult for AI. While on the other hand, complex computations difficult for the average human can be done in seconds by AI. This is known as Moravec’s paradox, where what seems simple to us is actually difficult for AI. \n",
    "\n",
    "Another concept that overlapped is seen at the start of Bennett's book where he referenced the show \"The Jetsons\" and how they predicted technology like mobile devices yet overestimated AI like \"Rosie the Robot\" having emotions. Mitchell in her paper, uses the term AI Summers to show huge investments in AI and AI winters where progress stalls as the anticipations made in the summer falls short. In other words, AI is a cycle of ups and downs filled with voices possibilities that end up coming to fruition. Ironically, Mitchell's first fallacy about AI study is how people tend to take one small step (climbing up a tree) to being significantly closer to (flying to the moon). \n",
    "\n",
    "Below is a list of the 4 fallacies. \n",
    "\n",
    "1. The belief that narrow successes translate to progress toward general intelligence.\n",
    "2. Assumption that easy tasks for humans mean easy tasks for machines.\n",
    "3. Wishful mnemonics. AI systems are often described in humanlike terms, but these machines do not understand in any human sense.\n",
    "4. Intelligence is solely in the brain and can be separated from the body, emotions, and the environment.\n",
    "\n",
    "However, the most interesting fallacy as it pertains to the book is the third fallacy about wishful mnemonics.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43c4d4d-08c8-46db-9129-d42f8a558c33",
   "metadata": {},
   "source": [
    "## Should we be comparing artificial intelligence and human intelligence? \n",
    "\n",
    "As I was reading this book I kept thinking about how AI's use statistical shortcuts in their data and fail outside those narrow contexts. By naming benchmarks such as “reading comprehension” or “language understanding,” we forcefully impose on ourselves the concept that machines possess general abilities that they do not.\n",
    "\n",
    "So, when using \"human intelligence\" as the benchmark, I wonder if we are trying to fit a square peg into a round hole. My question is not so much can we connect AI to human evolution but should we? Are we comparing apples to oranges? As Bennett was going through the formation of organisms I kept wondering how will this connect back to intelligence relevant to machines. After all, as said by the fourth fallacy, intelligence is also dependent on interactions with the environment and the body. \n",
    "\n",
    "As I read the book I will keep in mind the connections Bennett makes as he traces the 5 major breakthroughs in evolution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b96ee2f-f85c-432a-9b6c-5eca7a2cf56f",
   "metadata": {},
   "source": [
    "## An alternative? \n",
    "\n",
    "But for every rejection I know there should be an offer of an alternative.\n",
    "\n",
    "How should we study AI if not in relation to human intelligence?\n",
    "\n",
    "**Well, what about serving needs other than humans?**\n",
    "\n",
    "How might our thought of AI change if AI served AI? If AI served machines and automation. If AI served inanimate objects. If AI worked for pets and animals? I think if we expand outside of what can AI do for humans, I think it may allow us to explore concepts we wouldn't consider with AI and transcend limitations set on human knowledge. \n",
    "\n",
    "After all, if we are training AI to have human knowledge, then their purpose is obsolete in the face of the real thing. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
